{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb1dde1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "026568a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.appName(\"ModelTraining\")\n",
    "    .config(\"spark.executor.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e875570",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAININGDATA=\"training.1600000.processed.noemoticon.csv\"\n",
    "TESTINGDATA=\"testdata.manual.2009.06.14.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "859bd999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f858a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip trainingandtestdata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89a5cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"polarity FLOAT, id INT, date_time STRING, query STRING, user STRING, tweets STRING\"\n",
    "raw_training_data = spark.read.csv(\n",
    "    TRAININGDATA, schema=schema\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e49ed122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_train_df = raw_training_data.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5ac626",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cdbe84",
   "metadata": {},
   "source": [
    "We are going to use Stop Words, Lemmatization, Stemming and special characters replacement to clean our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a58bfb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from stop_words import ENGLISH_STOP_WORDS\n",
    "def cleaner(x, stemming):\n",
    "    text = str(x).lower()\n",
    "    s = re.sub(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', ' _ip_ ', text)\n",
    "    # Isolate punctuation\n",
    "    s = re.sub(r'([.\\(\\)\\!\\?\\-\\\\\\/\\,])', r' \\1 ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|•\"«\\n])', ' ', s)\n",
    "    # Replace numbers and symbols with language\n",
    "    s = s.replace('&', ' and ')\n",
    "    s = s.replace('@', ' at ')\n",
    "    s = s.replace('0', ' zero ')\n",
    "    s = s.replace('1', ' one ')\n",
    "    s = s.replace('2', ' two ')\n",
    "    s = s.replace('3', ' three ')\n",
    "    s = s.replace('4', ' four ')\n",
    "    s = s.replace('5', ' five ')\n",
    "    s = s.replace('6', ' six ')\n",
    "    s = s.replace('7', ' seven ')\n",
    "    s = s.replace('8', ' eight ')\n",
    "    s = s.replace('9', ' nine ')\n",
    "    tweet = re.sub(r\"can'?t\", ' can not', s)\n",
    "    tweet = re.sub(r\"n't\", ' not', tweet)\n",
    "    tweet = re.sub(r\"'s\", ' is', tweet)\n",
    "    tweet = re.sub(r\"i'm\", ' i am ', tweet)\n",
    "    tweet = re.sub(r\"'ll\", ' will', tweet)\n",
    "    tweet = re.sub(r\"'ve\", ' have', tweet)\n",
    "    tweet = re.sub(r\"'d\", ' would', tweet)\n",
    "    tweet = re.sub(r'\\&amp;|\\&gt;|&lt;|\\&', ' and ', tweet)\n",
    "    url = re.compile(r'(https?[^\\s]*)')\n",
    "    smile = re.compile(r'[8:=;][\\'`\\-]?[\\)d]+|[)d]+[\\'`\\-][8:=;]')\n",
    "    sad = re.compile(r'[8:=;][\\'`\\-]?\\(+|\\)+[\\'`\\-][8:=;]')\n",
    "    lol = re.compile(r'[8:=;][\\'`\\-]?p+')\n",
    "    tweet = re.sub(r'\\@[^\\s]+', ' U ', tweet)\n",
    "    tweet = url.sub(' ', tweet)\n",
    "    tweet = re.sub(r'\\/', ' ', tweet)\n",
    "    tweet = smile.sub(' H ', tweet)\n",
    "    tweet = lol.sub(' H ', tweet)\n",
    "    tweet = sad.sub(' S ', tweet)\n",
    "    tweet = re.sub(r'([\\!\\?\\.]){2,}', '\\g<1>', tweet)\n",
    "    tweet = re.sub(r'\\b(\\S*?)([^\\s])\\2{2,}\\b', '\\g<1>\\g<2>', tweet)\n",
    "    tweet = re.sub(r'\\#', ' #', tweet)\n",
    "    tweet = re.sub(r'[^\\w\\#\\s\\?\\<\\>]+', ' ', tweet)\n",
    "    tweet = re.sub('\\s+', ' ', tweet)\n",
    "    text = re.sub('\\[.*?\\]', '', tweet)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    chain = ''\n",
    "    if stemming == 'lemmatize':\n",
    "        chain = ' '.join([Word(word).lemmatize() for word in text.split(' ') if word not in ENGLISH_STOP_WORDS])\n",
    "    elif stemming == 'stemming':\n",
    "        chain = ' '.join([Word(word).stem() for word in text.split(' ') if word not in ENGLISH_STOP_WORDS])\n",
    "    else:\n",
    "        chain = ' '.join([word for word in text.split(' ') if word not in ENGLISH_STOP_WORDS])\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd2aab09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+--------------------+--------+---------------+--------------------+\n",
      "|polarity|        id|           date_time|   query|           user|              tweets|\n",
      "+--------+----------+--------------------+--------+---------------+--------------------+\n",
      "|     0.0|1467810369|Mon Apr 06 22:19:...|NO_QUERY|_TheSpecialOne_| switchfoot twitp...|\n",
      "|     0.0|1467810672|Mon Apr 06 22:19:...|NO_QUERY|  scotthamilton|upset update face...|\n",
      "|     0.0|1467810917|Mon Apr 06 22:19:...|NO_QUERY|       mattycus| kenichan dived t...|\n",
      "|     0.0|1467811184|Mon Apr 06 22:19:...|NO_QUERY|        ElleCTF|body feels itchy ...|\n",
      "|     0.0|1467811193|Mon Apr 06 22:19:...|NO_QUERY|         Karoli| nationwideclass ...|\n",
      "|     0.0|1467811372|Mon Apr 06 22:20:...|NO_QUERY|       joy_wolf|      kwesidei crew |\n",
      "|     0.0|1467811592|Mon Apr 06 22:20:...|NO_QUERY|        mybirch|           need hug |\n",
      "|     0.0|1467811594|Mon Apr 06 22:20:...|NO_QUERY|           coZZ| loltrish hey lon...|\n",
      "|     0.0|1467811795|Mon Apr 06 22:20:...|NO_QUERY|2Hood4Hollywood|  tatianak nope did |\n",
      "|     0.0|1467812025|Mon Apr 06 22:20:...|NO_QUERY|        mimismo| twittera que mue...|\n",
      "|     0.0|1467812416|Mon Apr 06 22:20:...|NO_QUERY| erinx3leannexo|spring break plai...|\n",
      "|     0.0|1467812579|Mon Apr 06 22:20:...|NO_QUERY|   pardonlauren|  just pierced ears |\n",
      "|     0.0|1467812723|Mon Apr 06 22:20:...|NO_QUERY|           TLeC| caregiving bear ...|\n",
      "|     0.0|1467812771|Mon Apr 06 22:20:...|NO_QUERY|robrobbierobert| octolinz counts ...|\n",
      "|     0.0|1467812784|Mon Apr 06 22:20:...|NO_QUERY|    bayofwolves| smarrison did gu...|\n",
      "|     0.0|1467812799|Mon Apr 06 22:20:...|NO_QUERY|     HairByJess| iamjazzyfizzle w...|\n",
      "|     0.0|1467812964|Mon Apr 06 22:20:...|NO_QUERY| lovesongwriter|hollis death scen...|\n",
      "|     0.0|1467813137|Mon Apr 06 22:20:...|NO_QUERY|       armotley|         file taxes |\n",
      "|     0.0|1467813579|Mon Apr 06 22:20:...|NO_QUERY|     starkissed| lettya ahh ive w...|\n",
      "|     0.0|1467813782|Mon Apr 06 22:20:...|NO_QUERY|      gi_gi_bee| fakerpattypattz ...|\n",
      "+--------+----------+--------------------+--------+---------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "raw_training_data.withColumn('tweets', f.udf(lambda x:cleaner(x, 'nature'))(\"tweets\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930d651b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b43f258",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8ebe84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5bb4707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a5ab74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c027eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ce1367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
