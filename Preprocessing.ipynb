{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06aac607",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install findspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb1dde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    " \n",
    "#import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026568a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as f\n",
    "\n",
    "import pyspark\n",
    "\n",
    "number_cores = 8\n",
    "memory_gb = 24\n",
    "\n",
    "#conf = (\n",
    "#    pyspark.SparkConf()\n",
    "#        .setMaster('local[{}]'.format(number_cores))\n",
    "#        .set('spark.driver.memory', '{}g'.format(memory_gb))\n",
    "#)\n",
    "#sc = pyspark.SparkContext(conf=conf)\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    ".appName(\"ModelTraining\")\\\n",
    ".master('local[{}]'.format(number_cores))\\\n",
    ".config(\"spark.executor.memory\", \"24g\")\\\n",
    ".getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e875570",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAININGDATA=\"training.1600000.processed.noemoticon.csv\"\n",
    "TESTINGDATA=\"testdata.manual.2009.06.14.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859bd999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f858a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip trainingandtestdata.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a5cef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = \"polarity FLOAT, id INT, date_time STRING, query STRING, user STRING, tweets STRING\"\n",
    "raw_training_data = spark.read.csv(\n",
    "    TRAININGDATA, schema=schema\n",
    ").cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ed122",
   "metadata": {},
   "outputs": [],
   "source": [
    "#raw_train_df = raw_training_data.toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5ac626",
   "metadata": {},
   "source": [
    "# Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cdbe84",
   "metadata": {},
   "source": [
    "We are going to use Stop Words, Lemmatization, Stemming and special characters replacement to clean our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a58bfb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from stop_words import ENGLISH_STOP_WORDS\n",
    "def cleaner(x, stemming):\n",
    "    text = str(x).lower()\n",
    "    s = re.sub(r'\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}', ' _ip_ ', text)\n",
    "    # Isolate punctuation\n",
    "    s = re.sub(r'([.\\(\\)\\!\\?\\-\\\\\\/\\,])', r' \\1 ', s)\n",
    "    # Remove some special characters\n",
    "    s = re.sub(r'([\\;\\:\\|•\"«\\n])', ' ', s)\n",
    "    # Replace numbers and symbols with language\n",
    "    s = s.replace('&', ' and ')\n",
    "    s = s.replace('@', ' at ')\n",
    "    s = s.replace('0', ' zero ')\n",
    "    s = s.replace('1', ' one ')\n",
    "    s = s.replace('2', ' two ')\n",
    "    s = s.replace('3', ' three ')\n",
    "    s = s.replace('4', ' four ')\n",
    "    s = s.replace('5', ' five ')\n",
    "    s = s.replace('6', ' six ')\n",
    "    s = s.replace('7', ' seven ')\n",
    "    s = s.replace('8', ' eight ')\n",
    "    s = s.replace('9', ' nine ')\n",
    "    tweet = re.sub(r\"can'?t\", ' can not', s)\n",
    "    tweet = re.sub(r\"n't\", ' not', tweet)\n",
    "    tweet = re.sub(r\"'s\", ' is', tweet)\n",
    "    tweet = re.sub(r\"i'm\", ' i am ', tweet)\n",
    "    tweet = re.sub(r\"'ll\", ' will', tweet)\n",
    "    tweet = re.sub(r\"'ve\", ' have', tweet)\n",
    "    tweet = re.sub(r\"'d\", ' would', tweet)\n",
    "    tweet = re.sub(r'\\&amp;|\\&gt;|&lt;|\\&', ' and ', tweet)\n",
    "    url = re.compile(r'(https?[^\\s]*)')\n",
    "    smile = re.compile(r'[8:=;][\\'`\\-]?[\\)d]+|[)d]+[\\'`\\-][8:=;]')\n",
    "    sad = re.compile(r'[8:=;][\\'`\\-]?\\(+|\\)+[\\'`\\-][8:=;]')\n",
    "    lol = re.compile(r'[8:=;][\\'`\\-]?p+')\n",
    "    tweet = re.sub(r'\\@[^\\s]+', ' U ', tweet)\n",
    "    tweet = url.sub(' ', tweet)\n",
    "    tweet = re.sub(r'\\/', ' ', tweet)\n",
    "    tweet = smile.sub(' H ', tweet)\n",
    "    tweet = lol.sub(' H ', tweet)\n",
    "    tweet = sad.sub(' S ', tweet)\n",
    "    tweet = re.sub(r'([\\!\\?\\.]){2,}', '\\g<1>', tweet)\n",
    "    tweet = re.sub(r'\\b(\\S*?)([^\\s])\\2{2,}\\b', '\\g<1>\\g<2>', tweet)\n",
    "    tweet = re.sub(r'\\#', ' #', tweet)\n",
    "    tweet = re.sub(r'[^\\w\\#\\s\\?\\<\\>]+', ' ', tweet)\n",
    "    tweet = re.sub('\\s+', ' ', tweet)\n",
    "    text = re.sub('\\[.*?\\]', '', tweet)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    chain = ''\n",
    "    if stemming == 'lemmatize':\n",
    "        chain = ' '.join([Word(word).lemmatize() for word in text.split(' ') if word not in ENGLISH_STOP_WORDS])\n",
    "    elif stemming == 'stemming':\n",
    "        chain = ' '.join([Word(word).stem() for word in text.split(' ') if word not in ENGLISH_STOP_WORDS])\n",
    "    else:\n",
    "        chain = ' '.join([word for word in text.split(' ') if word not in ENGLISH_STOP_WORDS])\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2aab09",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_data = raw_training_data.withColumn('tweets', f.udf(lambda x:cleaner(x, 'nature'))(\"tweets\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47febd1",
   "metadata": {},
   "source": [
    "# Plot our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e12ecd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb6e0b4",
   "metadata": {},
   "source": [
    "We check if classes are balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91107944",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_data.select(\"polarity\").toPandas().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccc8d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sb.distplot(clean_train_data.select(\"polarity\").toPandas())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6597665c",
   "metadata": {},
   "source": [
    "# Make a Train and Test samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee59e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_train_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c6d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7266a282",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean_train_data.select(\"tweets\").toPandas().to_numpy()\n",
    "y = clean_train_data.select(\"polarity\").toPandas().to_numpy()\n",
    "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.3, random_state=42)\n",
    "sss.get_n_splits(X, y)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3d62bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30122c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725e7497",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.DataFrame(X_train, columns=['tweets']).join(pd.DataFrame(y_train, columns=['polarity']))\n",
    "test = pd.DataFrame(X_test, columns=['tweets']).join(pd.DataFrame(y_test, columns=['polarity']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a72fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_to_spark_df (data):\n",
    "    return spark.createDataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d603598",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pandas_to_spark_df(train)\n",
    "test = pandas_to_spark_df(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d2b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.toPandas()['polarity'].value_counts(), test.toPandas()['polarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c027eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c5cd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824c488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ce1367",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (\n",
    "    Tokenizer,\n",
    "    HashingTF,\n",
    "    IDF,\n",
    ")\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml import Pipeline\n",
    "tokenizer = Tokenizer(inputCol=\"tweets\", outputCol=\"tokens\")\n",
    "hashing_tf = HashingTF(inputCol=\"tokens\", outputCol=\"term_frequency\")\n",
    "\n",
    "idf = IDF(\n",
    "    inputCol=\"term_frequency\",\n",
    "    outputCol=\"features\",\n",
    "    minDocFreq=5,  # minDocFreq: remove sparse terms\n",
    ")\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"polarity\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db674874",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    stages=[tokenizer, hashing_tf, idf, lr]\n",
    ")\n",
    "\n",
    "model = pipeline.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7981cc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "test_prediciton = semantic_analysis_model.transform(test)\n",
    "test_prediction.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778e196e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"polarity\", metricName=\"accuracy\")\n",
    "accuracy = evaluator.evaluate(test_prediction)\n",
    "print(f\"Model Accuracy: {accuracy*100:.5f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c71544a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069c5c1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59c4c16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d699f28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650d3052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d74afd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab1eeab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef51511",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568885aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15660aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4e85ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
